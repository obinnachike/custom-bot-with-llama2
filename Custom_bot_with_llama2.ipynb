{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOk+FgzccF2XK4/AA1ZjynV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/obinnachike/custom-bot-with-llama2/blob/main/Custom_bot_with_llama2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxjwrxWQXL9g"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain\n",
        "!pip -q install bitsandbytes accelerate transformers\n",
        "!pip -q install datasets loralib sentencepiece\n",
        "!pip -q install pypdf\n",
        "!pip -q install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install unstructured"
      ],
      "metadata": {
        "id": "krlPK4U3X0Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tokenizers"
      ],
      "metadata": {
        "id": "zeuhSg2fYJnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xformers"
      ],
      "metadata": {
        "id": "pnltnBgqYNkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "N70NVwxcZUcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import pipeline\n",
        "from langchain import HuggingFacePipeline\n",
        "from huggingface_hub import notebook_login\n",
        "import textwrap\n",
        "import sys\n",
        "import os\n",
        "import torch"
      ],
      "metadata": {
        "id": "9vKW9KGfYTIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "tW7tLgBZZQen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "URLs=[\n",
        "    'https://blog.gopenai.com/paper-review-llama-2-open-foundation-and-fine-tuned-chat-models-23e539522acb',\n",
        "    'https://www.mosaicml.com/blog/mpt-7b',\n",
        "    'https://stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models',\n",
        "    'https://lmsys.org/blog/2023-03-30-vicuna/'\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "AhzbLru9aHpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaders = UnstructuredURLLoader(urls=URLs)\n",
        "data = loaders.load()"
      ],
      "metadata": {
        "id": "JGWlHCaWaMnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "T7WTIHAMaP2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "u6fhQAJ4aTt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter=CharacterTextSplitter(separator='\\n',\n",
        "                                    chunk_size=1000,\n",
        "                                    chunk_overlap=200)"
      ],
      "metadata": {
        "id": "CvA7yc0daaK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks=text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "RFh6L8OVaeDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_chunks)"
      ],
      "metadata": {
        "id": "_uxKI07jagnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks"
      ],
      "metadata": {
        "id": "VfFdMgCUajYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks[0]"
      ],
      "metadata": {
        "id": "XFPRtNJkamkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks[1]"
      ],
      "metadata": {
        "id": "fd5eUndmar6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**5: Download the Hugging Face Embeddings**"
      ],
      "metadata": {
        "id": "fo4a8a5ga16-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "embeddings=HuggingFaceEmbeddings()"
      ],
      "metadata": {
        "id": "GSJdfAVIauXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings"
      ],
      "metadata": {
        "id": "6tJ2yVZLbMVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_result = embeddings.embed_query(\"How are you\")\n",
        "len(query_result)"
      ],
      "metadata": {
        "id": "W0g6T743bR7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_result"
      ],
      "metadata": {
        "id": "cO3GTH5fbX41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**06: Convert the Text Chunks into Embeddings and Create a Knowledge Base**"
      ],
      "metadata": {
        "id": "0tVh9-eIbihs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "nzsfUQ1kcIl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore=FAISS.from_documents(text_chunks, embeddings)"
      ],
      "metadata": {
        "id": "t5APKQ8ObaYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_name='llama'"
      ],
      "metadata": {
        "id": "Lz-H-8S2b1xB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore=FAISS.from_documents(text_chunks, embeddings)"
      ],
      "metadata": {
        "id": "A4ZPwUHocuO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save FAISS index to disk\n",
        "vectorstore.save_local(index_name)\n"
      ],
      "metadata": {
        "id": "2M3z7qFSc4ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**07: Create a Large Language Model (LLM) Wrapper**"
      ],
      "metadata": {
        "id": "-PMqL7KCfMGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "xKF5n88Be-Y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model=\"meta-llama/Llama-2-7b-chat-hf\"\n",
        "model=\"daryl149/llama-2-7b-chat-hf\""
      ],
      "metadata": {
        "id": "K7DIujTif5-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model,\n",
        "                                          use_auth_token=True,)\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model,\n",
        "                                             device_map='auto',\n",
        "                                             torch_dtype=torch.float16,\n",
        "                                             use_auth_token=True,\n",
        "                                              load_in_8bit=True,\n",
        "                                              #load_in_4bit=True\n",
        "                                             )"
      ],
      "metadata": {
        "id": "54Ke7ZFMgYb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"text-generation\",\n",
        "                model=model,\n",
        "                tokenizer= tokenizer,\n",
        "                torch_dtype=torch.bfloat16,\n",
        "                device_map=\"auto\",\n",
        "                max_new_tokens = 512,\n",
        "                do_sample=True,\n",
        "                top_k=30,\n",
        "                num_return_sequences=1,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "                )"
      ],
      "metadata": {
        "id": "tZtDpZhfgf35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=HuggingFacePipeline(pipeline=pipe, model_kwargs={'temperature':0})"
      ],
      "metadata": {
        "id": "WgHQZImmiWD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.predict(\"Please provide a concise summary of the Book Harry Potter\")"
      ],
      "metadata": {
        "id": "cgawLAs6iY28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**08: Initialize the Retrieval QA with Source Chain**"
      ],
      "metadata": {
        "id": "TnikdriDillq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "HyQke771ibp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How good is Vicuna?\""
      ],
      "metadata": {
        "id": "zoyJGgigipMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = vectorstore.similarity_search(query, k=3)"
      ],
      "metadata": {
        "id": "XvTr7gtDir2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "id": "YKo1v8KljcU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vectorstore.as_retriever())"
      ],
      "metadata": {
        "id": "IvVG7gSHjdiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How good is Vicuna?\"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "id": "Soc0EoQHjne6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How does Llama 2 outperforms other models\"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "id": "XWcBskBKj09O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  user_input = input(f\"Input Prompt: \")\n",
        "  if user_input == 'exit':\n",
        "    print('Exiting')\n",
        "    sys.exit()\n",
        "  if user_input == '':\n",
        "    continue\n",
        "  result = qa({'query': user_input})\n",
        "  print(f\"Answer: {result['result']}\")"
      ],
      "metadata": {
        "id": "XW28AAuGj-7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SmaQaz3XkYyc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}